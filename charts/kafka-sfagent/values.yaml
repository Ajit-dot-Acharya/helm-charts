# ------------------------------------------------------------------------------
# Kafka:
# ------------------------------------------------------------------------------

## The StatefulSet installs 3 pods by default
replicas: 3

## The kafka image repository
image: "mahendra0939/kafka-auditable"

## The kafka image tag
imageTag: "latest"

# Global application tags   
# sfappname_key and sfprojectname_key should be in lowercase. 
# sfappname: petclinic --> snappyflow/appname: kafka
# sfprojectname: spring --> snappyflow/projectname: kafka-project
global:
  sfappname: kafka
  sfprojectname: kafka-project
  sfappname_key: snappyflow/appname
  sfprojectname_key: snappyflow/projectname
  key: ""
## Specify a imagePullPolicy
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
imagePullPolicy: "IfNotPresent"

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
resources:
   requests:
     cpu: 200m
     memory: 1Gi
#   limits:
#     cpu: 200m
#     memory: 1536Mi
kafkaHeapOptions: "-Xmx1G -Xms1G"

## The StatefulSet Update Strategy which Kafka will use when changes are applied.
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy:
  type: "OnDelete"

## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
podManagementPolicy: OrderedReady

## If RBAC is enabled on the cluster, the Kafka init container needs a service account
## with permissisions sufficient to apply pod labels
rbac:
  enabled: true

## The name of the storage class which the cluster should use.
  storageClass: "slow"

## The subpath within the Kafka container's PV where logs will be stored.
## This is combined with `persistence.mountPath`, to create, by default: /opt/kafka/data/logs
logSubPath: "logs"

## Use an alternate scheduler, e.g. "stork".
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
# schedulerName:

## Pod scheduling preferences (by default keep pods within a release on separate nodes).
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
## By default we don't set affinity
affinity: {}
# Alternatively, this typical example defines:
# antiAffinity (to keep Kafka pods on separate pods)
# and affinity (to encourage Kafka pods to be collocated with Zookeeper pods)
# podAntiAffinity:
#   requiredDuringSchedulingIgnoredDuringExecution:
#   - labelSelector:
#       matchExpressions:
#       - key: app
#         operator: In
#         values:
#         - kafka
#     topologyKey: "kubernetes.io/hostname"
# podAffinity:
#   preferredDuringSchedulingIgnoredDuringExecution:
#    - weight: 50
#      podAffinityTerm:
#        labelSelector:
#          matchExpressions:
#          - key: app
#            operator: In
#            values:
#              - zookeeper
#        topologyKey: "kubernetes.io/hostname"

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}

## Readiness probe config.
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
##
readinessProbe:
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

## Period to wait for broker graceful shutdown (sigterm) before pod is killed (sigkill)
## ref: https://kubernetes-v1-4.github.io/docs/user-guide/production-pods/#lifecycle-hooks-and-termination-notice
## ref: https://kafka.apache.org/10/documentation.html#brokerconfigs controlled.shutdown.*
terminationGracePeriodSeconds: 60

# Tolerations for nodes that have taints on them.
# Useful if you want to dedicate nodes to just run kafka
# https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []
# tolerations:
# - key: "key"
#   operator: "Equal"
#   value: "value"
#   effect: "NoSchedule"

## External access.
##
external:
  enabled: false
  servicePort: 9092
  firstListenerPort: 31090
  domain: cluster.local
  init:
    image: "lwolf/kubectl_deployer"
    imageTag: "0.4"
    imagePullPolicy: "IfNotPresent"

## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
## here in map format, as defined in the official docs.
## ref: https://kafka.apache.org/documentation/#brokerconfigs
##
configurationOverrides:
  "offsets.topic.replication.factor": 3
  "auto.leader.rebalance.enable": true
  "auto.create.topics.enable": true
  "delete.topic.enable": true
  "num.partitions": 3
  "default.replication.factor": 2
  "log.retention.hours": 48
  "listener.security.protocol.map": |-
   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
  # "controlled.shutdown.enable": true
  # "controlled.shutdown.max.retries": 100

  ## Options required for external access via NodePort
  ## ref:
  ## - http://kafka.apache.org/documentation/#security_configbroker
  ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
  ##
  ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
  # "advertised.listeners": |-
  #   EXTERNAL://kafka.cluster.local:$((31090 + ${KAFKA_BROKER_ID}))
  # "listener.security.protocol.map": |-
  #   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

## A collection of additional ports to expose on brokers (formatted as normal containerPort yaml)
# Useful when the image exposes metrics (like prometheus, etc.) through a javaagent instead of a sidecar
additionalPorts: {}

## Persistence configuration. Specify if and how to persist data to a persistent volume.
##
persistence:
  enabled: true

  ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
  ## production servers this number should likely be much larger.
  ##
  size: "10Gi"

  ## The location within the Kafka container where the PV will mount its storage and Kafka will
  ## store its logs.
  ##
  mountPath: "/opt/kafka/data"

  ## Kafka data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: "slow"

# ------------------------------------------------------------------------------
# Zookeeper:
# ------------------------------------------------------------------------------

zookeeper:
  ## If true, install the Zookeeper chart alongside Kafka
  ## ref: https://github.com/kubernetes/charts/tree/master/incubator/zookeeper
  enabled: true

  servers: 3

  ## Configure Zookeeper resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 1
      memory: 1Gi

  ## The JVM heap size to allocate to Zookeeper
  heap: "1G"

  persistence:
    enabled: false
    ## The amount of PV storage allocated to each Zookeeper pod in the statefulset
    size: "4Gi"
    storageClass: "slow"
    mountPath: "/var/lib/zookeeper"

  ## Specify a Zookeeper imagePullPolicy
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  imagePullPolicy: "IfNotPresent"

  ## If the Zookeeper Chart is disabled a URL and port are required to connect
  url: ""
  port: 2181

  ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## By default we don't set affinity:
  affinity: {} # Criteria by which pod label-values influence scheduling for zookeeper pods.
#    podAntiAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       - topologyKey: "kubernetes.io/hostname"
#         labelSelector:
#           matchLabels:
#             release: zookeeper

nodeport:
  enabled: false
  servicePort: 19092
  firstListenerPort: 31090
# ------------------------------------------------------------------------------
# kafka perf generator
# ------------------------------------------------------------------------------

perf_test:
  enabled: true
  resources:
    requests:
      cpu: 200m
      memory: 200Mi
    limits:
      cpu: 512m
      memory: 512Mi
  throughput: 10
  num_messages: 5000
  topic: "perftest"
  group_name: "kafka_group"

# ------------------------------------------------------------------------------
# kafka logger
# ------------------------------------------------------------------------------
sfagent:
  enabled: true
  image: snappyflowml/sfagent
  imageTag: latest
  imagePullPolicy: Always
  resources:
    requests:
      cpu: 250m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
