# Default values for Log Archival.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
global:

  postgresql:
    host: ""
    postgresqlDatabase: new_archival
    postgresqlUsername: archive
    postgresqlPassword: archive123
    servicePort: 5432

  secrets:
    gcs:
      enable: false
      secret: XX
      key: XX.json
    aws:
      enable: true
      AWS_DEFAULT_REGION: us-west-2
      AWS_ACCESS_KEY_ID: XXXX
      AWS_SECRET_ACCESS_KEY: XXXX

  kafkaBrokers: ""

  snappyflowDatapath:
    enabled: true
    releaseName: sf-datapath

  hive:
    userName: ubuntu
    host: 127.0.0.1
    port: 10000
    auth: NONE

  snappyflowProjectLabel: snappyflow/projectname
  snappyflowAppLabel: snappyflow/appname

  snappyflowProjectName: ""
  snappyflowAppName: ""

  imagePullSecrets:
  - name: xxxx

ingest-controller:

  containerResources:
    ingestcontroller:
      limits:
        cpu: 100m
        memory: 200Mi
      requests:
        cpu: 50m
        memory: 100Mi
    schemacreate:
      limits:
        cpu: 50m
        memory: 50Mi
      requests:
        cpu: 50m
        memory: 50Mi

compaction-controller:

  MasterUrl: "k8s://kubernetes.default.svc:443"

  containerResources:
    compaction:
      limits:
        cpu: 100m
        memory: 200Mi
      requests:
        cpu: 50m
        memory: 100Mi

dataset-controller:

  billing-service:
    url: 127.0.0.1:8000/api/v1/records/
    scheme: https

  containerResources:
    datasetcontroller:
      limits:
        cpu: 100m
        memory: 200Mi
      requests:
        cpu: 50m
        memory: 100Mi
    uncompactedcleanup:
      limits:
        cpu: 100m
        memory: 200Mi
      requests:
        cpu: 50m
        memory: 100Mi

spark-manager:

  monitor:
    containerResources:
      limits:
        cpu: 100m
        memory: 200Mi
      requests:
        cpu: 50m
        memory: 100Mi

  jobserver:
    sparkProperties:
      logDirectory: sparkhs/spark-hs/
    containerResources:
      limits:
        cpu: 200m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 512Mi

postgresql:

  enabled: false

  metrics:
    enabled: true

  containerResources:
    postgres:
      requests:
        memory: 256Mi
        cpu: 250m
      limits:
        memory: 512Mi
        cpu: 500m
    exporter:
      requests:
        memory: 100Mi
        cpu: 100m
      limits:
        memory: 100Mi
        cpu: 100m


log-archival:

  containerResources:
    logarchival:
      limits:
        cpu: 50m
        memory: 50Mi
      requests:
        cpu: 50m
        memory: 50Mi

query-controller:

  prestoUser: ubuntu

  prestoCatalog: hive

  prestoSchema: default

  containerResources:
    querycontroller:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 150Mi
    queryexecutioncontroller:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 150Mi
    querycleanup:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 150Mi

cron:

  containerResources:
    cron:
      limits:
        cpu: 25m
        memory: 50Mi
      requests:
        cpu: 10m
        memory: 25Mi

spark-history-server:

  enabled: false

  s3:
    logDirectory: sparkhs/spark-hs/
